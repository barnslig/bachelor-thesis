{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Protocol: Maximum Size Hash table\n",
    "\n",
    "Date: 16.09.2021\n",
    "\n",
    "## Question\n",
    "\n",
    "Does increasing the Grapple hash table size to full 48 KB (shared memory maximum size) increase Waypoint Discovery in relation to the executed VTs such that it is similar to the results from the Grapple paper?\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "As the hash table capacity significantly affects the state space coverage, having the same hash table capacity as in the paper allows reproduction of their results.\n",
    "\n",
    "## Setup\n",
    "\n",
    "- GPU: NVIDIA GeForce RTX 2080 Ti\n",
    "- Program: `main` branch, commit e160572 and `feature/EXP-02-max-size-hash-table` branch, commit c9cd0ec\n",
    "- Model: Waypoints model\n",
    "- CUDA_FLAGS: `-DGRAPPLE_MODEL=WaypointsState`\n",
    "\n",
    "## Implementation\n",
    "\n",
    "For each experiment, we execute 80 runs Ã  250 VTs (= 20000 VTs).\n",
    "\n",
    "First, we run our implementation (`main` branch) that can store $2^{18} = 262144$ states in its hash table.\n",
    "\n",
    "```\n",
    "$ time ./build/grapple -s 1736331306 -n 80\n",
    "run,block,thread,state,uniques,visited,visited_percent,vts,total_visited\n",
    "...\n",
    "79,,,,,4.74347e+08,11.0443,20000,63568607\n",
    "\n",
    "real    0m35.464s\n",
    "user    0m35.198s\n",
    "sys     0m0.184s\n",
    "```\n",
    "\n",
    "Full output data is available at [EXP-02-large-hash-table-1.csv](./data/EXP-02-large-hash-table-1.csv).\n",
    "\n",
    "---\n",
    "\n",
    "Then, we run the maximum-size hash table (`feature/max-size-hash-table` branch) that can store $393056$ states in its hash table.\n",
    "\n",
    "```\n",
    "$ time ./build/grapple -s 1736331306 -n 80\n",
    "run,block,thread,state,uniques,visited,visited_percent,vts,total_visited\n",
    "...\n",
    "79,,,,,9.9405e+08,23.1445,20000,91937680\n",
    "\n",
    "real    0m50.373s\n",
    "user    0m50.098s\n",
    "sys     0m0.208s\n",
    "```\n",
    "\n",
    "Full output data is available at [EXP-02-large-hash-table-2.csv](./data/EXP-02-large-hash-table-2.csv).\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "The larger hash table (2nd experiment) yields 2.1x as many visited states. ($23/11 \\approx 2.1$)\n",
    "\n",
    "The larger hash table in total only visits 1.45x as many states as the smaller one. ($91937680/63568607 \\approx 1.45$)\n",
    "\n",
    "In the paper, a Grapple Swarm Verification with 32 threads (called *Full-Warp*) and 392800 hash table slots per VT discovers 85 Waypoints, equalling 85% state space coverage, after 20000 VTs. This is about 3.7x as many as our large-size hash table implementation, which only explores 23% of the state space in 20000 VTs. (column `visited_percent` in the output above)\n",
    "\n",
    "## Conclusion, Discussion\n",
    "\n",
    "On this particular model, a larger hash table seems beneficial, as the state space coverage can be more than doubled visiting only 1.45x the states.\n",
    "\n",
    "Even though our large-size hashtable is slightly larger than the one supposedly used in the paper, we are far from reproducing its results.\n",
    "\n",
    "Thus, our hypothesis cannot be confirmed."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "plaintext"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}